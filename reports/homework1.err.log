Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/nbclient/client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/nbclient/client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')

### YOUR CODE HERE ###
------------------

----- stderr -----
Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]
----- stderr -----
Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.35k/1.35k [00:00<00:00, 292kB/s]
----- stderr -----

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[3], line 1[0m
[0;32m----> 1[0m generator [38;5;241m=[39m [43mpipeline[49m[43m([49m[38;5;124;43m'[39;49m[38;5;124;43mtext-generation[39;49m[38;5;124;43m'[39;49m[43m,[49m[43m [49m[43mmodel[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mEleutherAI/gpt-neo-1.3B[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m      3[0m [38;5;66;03m### YOUR CODE HERE ###[39;00m

File [0;32m/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/transformers/pipelines/__init__.py:834[0m, in [0;36mpipeline[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)[0m
[1;32m    832[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(model, [38;5;28mstr[39m) [38;5;129;01mor[39;00m framework [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    833[0m     model_classes [38;5;241m=[39m {[38;5;124m"[39m[38;5;124mtf[39m[38;5;124m"[39m: targeted_task[[38;5;124m"[39m[38;5;124mtf[39m[38;5;124m"[39m], [38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m: targeted_task[[38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m]}
[0;32m--> 834[0m     framework, model [38;5;241m=[39m [43minfer_framework_load_model[49m[43m([49m
[1;32m    835[0m [43m        [49m[43mmodel[49m[43m,[49m
[1;32m    836[0m [43m        [49m[43mmodel_classes[49m[38;5;241;43m=[39;49m[43mmodel_classes[49m[43m,[49m
[1;32m    837[0m [43m        [49m[43mconfig[49m[38;5;241;43m=[39;49m[43mconfig[49m[43m,[49m
[1;32m    838[0m [43m        [49m[43mframework[49m[38;5;241;43m=[39;49m[43mframework[49m[43m,[49m
[1;32m    839[0m [43m        [49m[43mtask[49m[38;5;241;43m=[39;49m[43mtask[49m[43m,[49m
[1;32m    840[0m [43m        [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mhub_kwargs[49m[43m,[49m
[1;32m    841[0m [43m        [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mmodel_kwargs[49m[43m,[49m
[1;32m    842[0m [43m    [49m[43m)[49m
[1;32m    844[0m model_config [38;5;241m=[39m model[38;5;241m.[39mconfig
[1;32m    845[0m hub_kwargs[[38;5;124m"[39m[38;5;124m_commit_hash[39m[38;5;124m"[39m] [38;5;241m=[39m model[38;5;241m.[39mconfig[38;5;241m.[39m_commit_hash

File [0;32m/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/transformers/pipelines/base.py:220[0m, in [0;36minfer_framework_load_model[0;34m(model, config, model_classes, task, framework, **model_kwargs)[0m
[1;32m    194[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[1;32m    195[0m [38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).[39;00m
[1;32m    196[0m 
[0;32m   (...)[0m
[1;32m    217[0m [38;5;124;03m    `Tuple`: A tuple framework, model.[39;00m
[1;32m    218[0m [38;5;124;03m"""[39;00m
[1;32m    219[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m is_tf_available() [38;5;129;01mand[39;00m [38;5;129;01mnot[39;00m is_torch_available():
[0;32m--> 220[0m     [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(
[1;32m    221[0m         [38;5;124m"[39m[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. [39m[38;5;124m"[39m
[1;32m    222[0m         [38;5;124m"[39m[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ [39m[38;5;124m"[39m
[1;32m    223[0m         [38;5;124m"[39m[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.[39m[38;5;124m"[39m
[1;32m    224[0m     )
[1;32m    225[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(model, [38;5;28mstr[39m):
[1;32m    226[0m     model_kwargs[[38;5;124m"[39m[38;5;124m_from_pipeline[39m[38;5;124m"[39m] [38;5;241m=[39m task

[0;31mRuntimeError[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.

