# Reinforcement Learning (part 2)

This session provides a deeper dive into reinforcement learning. In particular, this session introduces the formal framework which is used in RL, the Markov Decision Processes (MDPs).The session provides a brief overview of value functions which can be used to solve MDPs, and then focuses on motivating and introducing *policy-gradient methods*. These methods are commonly use when fine-tuning language models with RL.

The goal of the session is to provide a more formal introduction to core concepts in RL and to introduce the technical underpinnings of methods used for fine-tuning LLMs with RL.


Slides for the session can be found [here](<https://polina-tsvilodub.github.io/RL4-language-model-training/03a-RL.pdf>).

## Further materials (optional)

Below, further materials on transformers, language model training, decoding schemes and basic RL concepts can be found.

* [**Sutton & Barto (2018). Reinforcement learning: An Introduction.**](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf)
* [Great YouTube video series on RL by Pieter Abbeel](https://youtu.be/2GwBez0D20A?si=D4toGoTbQu01qP5j)