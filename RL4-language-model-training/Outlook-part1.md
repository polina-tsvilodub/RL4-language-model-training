# Outlook: LLMs

In this session, we take a brief detour to systems which are more complex than "just consisting of an LLM". Specifically, due to their improved performance on various tasks beyond sentence completion and due to the amount of ‘general world knowledge’ that modern LLMs seem to encode, more and more larger architectures / systems have started using LLMs as building blocks. Such systems use LLMs for various purposes, from sentence generation and formatting, over planning tasks to coding assistance, and special packages like `LangChain` have been built to facilitate integrating LLMs within larger systems. 

Conversely, one can view these systems as LLMs augmented with various tools; such LLMs are sometimes called *agents*. Presentations this week will showcase two systems with different purposes where modern LLMs are used as core components of more complicated systems.

Furthermore, the session provides a brief outlook to conceptual discussion surrounding LLMs, their nature, and to which extent current fine-tuning techniques might contribute to safety.

The slides for the session can be found [here](<https://polina-tsvilodub.github.io/RL4-language-model-training/12a-Agents-outlook.pdf>).

## Student presentations

* [Park et al. (2023). Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)
* [Ahn et al. (2022). Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://arxiv.org/pdf/2204.01691.pdf)